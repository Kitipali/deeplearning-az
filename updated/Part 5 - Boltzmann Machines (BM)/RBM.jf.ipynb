{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a67ba7-9ea1-4730-a8b5-ad2af6effc2b",
   "metadata": {},
   "source": [
    "## Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6018deb-b925-4180-a577-27a69b5cb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías\n",
    "\n",
    "import numpy as np # Tratamiento numerico y matrices\n",
    "import pandas as pd # Importar dataset y crear conjunto de entrenamiento y test\n",
    "import torch\n",
    "import torch.nn as nn # redes neuronales\n",
    "import torch.nn.parallel # para crear cálculos en paralelo -> Optimización\n",
    "import torch.optim as optim # Optimizador para minimizar nuestro error\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da10070-f494-4cc9-b34b-213d8ac875a2",
   "metadata": {},
   "source": [
    "## Importar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddd620b-478d-4498-807a-e9ab8d16d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el dataset\n",
    "\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep = \"::\", header =None, engine = 'python', encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba37c642-14f3-40f8-b804-5415b06f17f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb0370d-3dda-4b1d-bf6e-4a9e55ad8bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215a55a4-1203-4e55-a607-d08d4d9aef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"ml-1m/users.dat\", sep = \"::\", header =None, engine = 'python', encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a135ba09-d81c-4f2c-876f-f045fd7fd80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc40d76f-dfb6-4b5e-97a3-d567b372be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb80779-b9d8-4318-8c4c-e26927ef1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep = \"::\", header =None, engine = 'python', encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f898735d-49af-446f-a8e7-bb7c62b5b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1b0103-df74-4cf4-9103-7dab51e24e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69ba49-7b1a-4eef-be77-a79866f2d156",
   "metadata": {},
   "source": [
    "## Preparar los conjuntos de entrenamiento y de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeabc950-319b-427a-8d8a-fc2ff0b7a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv( 'ml-100k/u1.base', sep ='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448128af-2731-4089-9478-a9046cd93ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9477e9b9-69c5-41ad-bbdb-9e40a9159812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch no acepta DataFrames sino arrays. Tenemos que reconvertirlo con numpy\n",
    "\n",
    "training_set = np.array(training_set, dtype = \"int\") #no queremos que sea int64 sino int porque pytorch lo entiende mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a932fc44-5971-44c5-88bc-44e6798758f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv( 'ml-100k/u1.test', sep ='\\t', header = None)\n",
    "test_set = np.array(training_set, dtype = \"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3529c030-57e9-4b1c-962c-07ba4429f079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be149d31-621a-4b8b-8805-d91bdc5b23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd1288-0a52-4b41-a019-3e0afc2af7ed",
   "metadata": {},
   "source": [
    "## Obtener el número de usuarios y de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d7cfce7-1552-4694-b3c3-5a1b0c92baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "#Por que no sé si el usuario más alto está en el conjunto de test o de traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d8f0c9d-1a43-4e7f-83f7-f15467ab0d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c129e280-664f-4f74-aa64-0cc291b361c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc739c52-a47a-4711-ac04-f29bd698fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a00a2-5e5a-46fa-a152-eb4329e1dfe2",
   "metadata": {},
   "source": [
    "## Convertir los datos en un array X[u,i] con usuarios u en fila y películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca0b9e45-3739-4676-922e-abffe16d953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_user in range(1, nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0]==id_user]\n",
    "        id_ratings = data[:,2][data[:,0]==id_user]\n",
    "        # Tb quiero un cero en las pelis que no ha clasificado -> Inicializo con 1682 ceros\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "012c827e-f6fe-4186-87f1-bf3b0737316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77535611-e70b-4b00-a409-59660ddca010",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980ebf8-5aac-4537-ba60-a22c1587e6b1",
   "metadata": {},
   "source": [
    "## Convertir los datos a tensores de Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab2962-4a71-4f47-a7f9-f54c0a831aab",
   "metadata": {},
   "source": [
    "Un tensor es una matriz multidimensional de un solo tipo de dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2ac8d0e-d213-4646-83dc-e73db9fcf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set= torch.FloatTensor(training_set)\n",
    "test_set= torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d79b3-e7f3-4519-b6e6-a4c975310240",
   "metadata": {},
   "source": [
    "## ->Parte exclusiva Máquinas de Boltzmann (Paso 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06a6c8-b89c-4633-b413-b37aa57d6bf5",
   "metadata": {},
   "source": [
    "## Convertir las valoraciones a valores binarios 1 (Me gusta) o 0 (No me gusta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca3ad6-ff3a-4769-a4bd-1494575b913c",
   "metadata": {},
   "source": [
    "Hasta aquí los ceros no significan nada. Como queremos que el cero signifique \"No me gusta\", tenemos que cambiar los ceros actuales por otra cosa -> -1. los  -1 serán las pelis no vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae9a52b2-dea9-40e9-9e3a-f51f163ecc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pelis no vistas\n",
    "training_set[training_set == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e96535c-988c-453f-a59e-1a0e5aa78a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos las puntuaciones de 1 y 2 como no me gusta.Pytorch no acepta Os (or)\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ebfaa90-c5c2-44cd-814b-a00bc7e70478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las pelis con puntuaciones mayores o iguales a 3 ->Me gusta\n",
    "training_set[training_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2fed1d8-d672-4ee7-8bcc-bff9cf5830d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos lo mismo para el test_set\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca078af-8424-4c75-a79a-0d99581b6cf0",
   "metadata": {},
   "source": [
    "## Crear la arquitectura de la Red Neuronal (Modelo Probabilístico Gráfico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1aa9e-c56a-4862-b9b7-de9b66128414",
   "metadata": {},
   "source": [
    "Tenemos que crear una Clase que indique el número de nodos ocultos, los pesos de los mismos, los pesos de la probabilidad de un nodo visible, el sego (byas, el término independiente)...\n",
    "Eato es la fórmula de los ai bi wij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f91c58a-fbc0-4914-b2ee-0bc5714eb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh): #nv: nº de nodos visibles; nd: nº de nodos ocultos\n",
    "        self.W= torch.randn(nh, nv) \n",
    "        #los pesos: aquí están las probabilidades que se asignan entre los nodos de capas visible y oculta\n",
    "        #Los pesos se inician primero aleatoriamente con valores pequeños pero no nulos. Se distribuirán siguiendo una Normal estandar (medio cero, varianza 1)\n",
    "        #El tensor tiene que ser de tamaño nh x nv para poder conectar la entrada de los nodos visibles con los ocultos\n",
    "        self.a= torch.randn(1, nh) \n",
    "        #inicializamos el sesgo (término independiente). \n",
    "        #Hay que otorgar una dimensión más quer tiene que ver con la iteración -> Vector bidimensional\n",
    "        self.b= torch.randn(1, nv)\n",
    "        #definimos el sesgo específico para la capa de salida a través de los nodos visibles)- Vector bidimensional\n",
    "    # 2ªfunción \"de muestreo\" que testeará los nodos de la capa oculta según las probabilidades (ph dado v) donde h es el nodo oculto y v el visible.\n",
    "    # Y luego podremos comprobar que esos nodos se activarán o no en función de los valores de esa probabilidad\n",
    "    def sample_h(self, x): # x -> valores de la capa visible (observaciones de los usuarios). No es v porque no tienen por qué ser todos\n",
    "        wx = torch.mm(x, self.W.t()) #mini_batch size x nh\n",
    "        # en torch hacemos así multiplicacion de dos matrices (tensores) como x es (1,nv) y W es (nh,nv) tengo que transponer W para poder hacer el producto\n",
    "        # Añadimos la función de activación\n",
    "        # wx -> ahora es (1, nh) -> igual que a. Así podemos sumarlos ahora. Pero si viene por bloques el vector a tiene que expandirse en la misma dimensión\n",
    "        activation= wx + self.a.expand_as(wx) # combinación lineal de los pesos y sesgos\n",
    "        p_h_given_v = torch.sigmoid(activation)    # aplicamos la función sigmoide al vector anterior. Generamos una muestra que active algunos de estos nodos\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v) # devolvemos una muestra de bernoulli de esta distribución construida a partir de las probabilidades\n",
    "    # 3ª función: en base a la probabilidad de que se active un nodo visible muestrearemos qué nodos de la capa visible deben activarse\n",
    "    def sample_v(self, y): # x -> valores de la capa oculta. No es h porque no tienen por qué ser todos\n",
    "        wy = torch.mm(y, self.W) #  #mini_batch size x nv Aquí no hace falta transponer porque y es (1,nh) y W es (nh,nv)\n",
    "        # en torch hacemos así multiplicacion de dos matrices (tensores)\n",
    "        # Añadimos la función de activación\n",
    "        # wy -> ahora es (1, nh) -> igual que a. Así podemos sumarlos ahora. Pero si viene por bloques el vector a tiene que expandirse en la misma dimensión\n",
    "        activation= wy + self.b.expand_as(wy) # combinación lineal de los pesos y sesgos\n",
    "        p_v_given_h = torch.sigmoid(activation)    #Probabilidad de activación de los nodos visibles conociendo los nodos ocultos\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h) # devolvemos una muestra de bernoulli de esta distribución construida a partir de las probabilidades\n",
    "    # 4ª función:Divergencia Contrastante\n",
    "    #Minimizar la función de energía  = maximizar el logaritmo de la probabilidad -> Lo aproximamos con la técnica de la divergencia contrastante\n",
    "    def train(self,v0, vk, ph0, phk): #v0 ->el valor original vk, nodos visibles despues de k pasos, ph0-> probabilidades de la primera iteración de los nodos ocultos dados los valores de los visibles, phk-> probabilidad de los nodos ocultos después de k iteraciones (k divergencias contrastantes)\n",
    "        self.W += (torch.mm(v0.t(),ph0) -torch.mm(vk.t(),phk)).t()\n",
    "        self.b +=torch.sum((v0-vk),0)\n",
    "        self.a +=torch.sum((ph0-phk),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b47bf6d-aa40-45f1-adf3-3509fbb16fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49e1dbdc-20af-4dfc-b4ba-45b95eac2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 100 # es un  parámetro que podemos elegir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c65fd35d-bce8-4dfd-a904-236af03ac925",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4585b1b-ec8f-4c73-be2b-bf7463187d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199eb17-f334-4310-8350-e4be9e702550",
   "metadata": {},
   "source": [
    "## Entrenar la RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14aa43e2-a5d4-4568-907d-2c890da3fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: tensor(0.3697)\n",
      "Epoch: 2, Loss: tensor(0.2519)\n",
      "Epoch: 3, Loss: tensor(0.2511)\n",
      "Epoch: 4, Loss: tensor(0.2599)\n",
      "Epoch: 5, Loss: tensor(0.2485)\n",
      "Epoch: 6, Loss: tensor(0.2485)\n",
      "Epoch: 7, Loss: tensor(0.2452)\n",
      "Epoch: 8, Loss: tensor(0.2475)\n",
      "Epoch: 9, Loss: tensor(0.2483)\n",
      "Epoch: 10, Loss: tensor(0.2429)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch= 10\n",
    "for epoch in range (1, nb_epoch+1):\n",
    "    training_loss = 0\n",
    "    s= 0.\n",
    "    for id_user in range(0,nb_users-batch_size, batch_size): \n",
    "        #v0 será el mismo (valoraciones originales de los usuarios) y vk irá cambiando a medida que hacemos el muestreo de Gibbs\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        #ph0 probabilidad de que un nodo oculto se active conociendo la entrada\n",
    "        ph0,_ = rbm.sample_h(v0) \n",
    "        for k in range(10):\n",
    "            #Hay que meter la divergencia contrastante en k pasos\n",
    "            _,hk = rbm.sample_h(vk) # nos da lps nodos ocultos que se actiuvan en el paso k-ésimo\n",
    "            _,vk = rbm.sample_v(hk) # nos calcula el nod visibles a partir del késimo nodo oculto -> actualiza vk\n",
    "            # ¿Qué hacer con los -1? -> Lo mantenemos en -1\n",
    "            vk[v0 <0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        training_loss += torch.mean(torch.abs(v0[v0>=0]-vk[vk>=0])) #Aquí sólo tengo encuenta las valoraciones en las que no hay -1\n",
    "        s += 1.\n",
    "    print(\"Epoch: \"+str(epoch)+\", Loss: \"+str(training_loss/s)) # divido por s por que si no el error total sube con cada iteración\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c7341-6748-4219-b93d-cff3d831feda",
   "metadata": {},
   "source": [
    "v0 = las valoraciones originales de ese batch de usuarios.\n",
    "Es tu “verdad”.\n",
    "\n",
    "vk = una copia inicial de v0, que luego se irá degradando, modificando, reconstruyendo durante el muestreo de Gibbs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74d939-d6de-4750-b991-db87a32c5e6f",
   "metadata": {},
   "source": [
    "## Testear la RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "494dbf82-1b6b-43d0-b858-9079f2aa4934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: tensor(0.2889)\n",
      "Testing Loss: tensor(0.2069)\n",
      "Testing Loss: tensor(0.3165)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2723)\n",
      "Testing Loss: tensor(0.2618)\n",
      "Testing Loss: tensor(0.2626)\n",
      "Testing Loss: tensor(0.2673)\n",
      "Testing Loss: tensor(0.2746)\n",
      "Testing Loss: tensor(0.2567)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2619)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2606)\n",
      "Testing Loss: tensor(0.2570)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2601)\n",
      "Testing Loss: tensor(0.2663)\n",
      "Testing Loss: tensor(0.2652)\n",
      "Testing Loss: tensor(0.2626)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2465)\n",
      "Testing Loss: tensor(0.2510)\n",
      "Testing Loss: tensor(0.2491)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2468)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2473)\n",
      "Testing Loss: tensor(0.2485)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2558)\n",
      "Testing Loss: tensor(0.2579)\n",
      "Testing Loss: tensor(0.2561)\n",
      "Testing Loss: tensor(0.2615)\n",
      "Testing Loss: tensor(0.2646)\n",
      "Testing Loss: tensor(0.2682)\n",
      "Testing Loss: tensor(0.2648)\n",
      "Testing Loss: tensor(0.2658)\n",
      "Testing Loss: tensor(0.2648)\n",
      "Testing Loss: tensor(0.2651)\n",
      "Testing Loss: tensor(0.2653)\n",
      "Testing Loss: tensor(0.2595)\n",
      "Testing Loss: tensor(0.2607)\n",
      "Testing Loss: tensor(0.2603)\n",
      "Testing Loss: tensor(0.2636)\n",
      "Testing Loss: tensor(0.2675)\n",
      "Testing Loss: tensor(0.2660)\n",
      "Testing Loss: tensor(0.2641)\n",
      "Testing Loss: tensor(0.2627)\n",
      "Testing Loss: tensor(0.2640)\n",
      "Testing Loss: tensor(0.2647)\n",
      "Testing Loss: tensor(0.2648)\n",
      "Testing Loss: tensor(0.2637)\n",
      "Testing Loss: tensor(0.2628)\n",
      "Testing Loss: tensor(0.2617)\n",
      "Testing Loss: tensor(0.2598)\n",
      "Testing Loss: tensor(0.2610)\n",
      "Testing Loss: tensor(0.2617)\n",
      "Testing Loss: tensor(0.2612)\n",
      "Testing Loss: tensor(0.2601)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2576)\n",
      "Testing Loss: tensor(0.2575)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2569)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2558)\n",
      "Testing Loss: tensor(0.2578)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2572)\n",
      "Testing Loss: tensor(0.2577)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2579)\n",
      "Testing Loss: tensor(0.2565)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2503)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2497)\n",
      "Testing Loss: tensor(0.2505)\n",
      "Testing Loss: tensor(0.2500)\n",
      "Testing Loss: tensor(0.2500)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2505)\n",
      "Testing Loss: tensor(0.2490)\n",
      "Testing Loss: tensor(0.2488)\n",
      "Testing Loss: tensor(0.2488)\n",
      "Testing Loss: tensor(0.2485)\n",
      "Testing Loss: tensor(0.2467)\n",
      "Testing Loss: tensor(0.2473)\n",
      "Testing Loss: tensor(0.2460)\n",
      "Testing Loss: tensor(0.2467)\n",
      "Testing Loss: tensor(0.2470)\n",
      "Testing Loss: tensor(0.2479)\n",
      "Testing Loss: tensor(0.2483)\n",
      "Testing Loss: tensor(0.2493)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2498)\n",
      "Testing Loss: tensor(0.2495)\n",
      "Testing Loss: tensor(0.2497)\n",
      "Testing Loss: tensor(0.2496)\n",
      "Testing Loss: tensor(0.2486)\n",
      "Testing Loss: tensor(0.2482)\n",
      "Testing Loss: tensor(0.2484)\n",
      "Testing Loss: tensor(0.2493)\n",
      "Testing Loss: tensor(0.2488)\n",
      "Testing Loss: tensor(0.2508)\n",
      "Testing Loss: tensor(0.2502)\n",
      "Testing Loss: tensor(0.2496)\n",
      "Testing Loss: tensor(0.2496)\n",
      "Testing Loss: tensor(0.2499)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2508)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2506)\n",
      "Testing Loss: tensor(0.2502)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2558)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2597)\n",
      "Testing Loss: tensor(0.2597)\n",
      "Testing Loss: tensor(0.2606)\n",
      "Testing Loss: tensor(0.2618)\n",
      "Testing Loss: tensor(0.2613)\n",
      "Testing Loss: tensor(0.2614)\n",
      "Testing Loss: tensor(0.2605)\n",
      "Testing Loss: tensor(0.2601)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2585)\n",
      "Testing Loss: tensor(0.2592)\n",
      "Testing Loss: tensor(0.2585)\n",
      "Testing Loss: tensor(0.2578)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2596)\n",
      "Testing Loss: tensor(0.2599)\n",
      "Testing Loss: tensor(0.2590)\n",
      "Testing Loss: tensor(0.2586)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2601)\n",
      "Testing Loss: tensor(0.2613)\n",
      "Testing Loss: tensor(0.2612)\n",
      "Testing Loss: tensor(0.2605)\n",
      "Testing Loss: tensor(0.2601)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2596)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2597)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2589)\n",
      "Testing Loss: tensor(0.2590)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2590)\n",
      "Testing Loss: tensor(0.2590)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2575)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2592)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2586)\n",
      "Testing Loss: tensor(0.2585)\n",
      "Testing Loss: tensor(0.2581)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2582)\n",
      "Testing Loss: tensor(0.2586)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2591)\n",
      "Testing Loss: tensor(0.2586)\n",
      "Testing Loss: tensor(0.2582)\n",
      "Testing Loss: tensor(0.2581)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2582)\n",
      "Testing Loss: tensor(0.2576)\n",
      "Testing Loss: tensor(0.2579)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2583)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2585)\n",
      "Testing Loss: tensor(0.2581)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2566)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2567)\n",
      "Testing Loss: tensor(0.2569)\n",
      "Testing Loss: tensor(0.2569)\n",
      "Testing Loss: tensor(0.2567)\n",
      "Testing Loss: tensor(0.2565)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2559)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2561)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2566)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2571)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2566)\n",
      "Testing Loss: tensor(0.2563)\n",
      "Testing Loss: tensor(0.2563)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2559)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2563)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2559)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2555)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2553)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2548)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2528)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testing_loss = 0\n",
    "s= 0.\n",
    "for id_user in range(nb_users): \n",
    "\n",
    "    v = training_set[id_user:id_user+1]# utilizamos conjunto de entrenamiento para activar neuronas\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0])>0:\n",
    " \n",
    " # Me basta un solo paso\n",
    " \n",
    "        _,h = rbm.sample_h(v) \n",
    "        _,v = rbm.sample_v(h) \n",
    "      \n",
    "        testing_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
    "        s += 1.\n",
    "        print(\"Testing Loss: \"+str(testing_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c64a1728-c41b-4ddd-9535-378c67fdf273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909a50d-c265-4f99-91c1-d5e2f195d293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_torch)",
   "language": "python",
   "name": "dl_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
